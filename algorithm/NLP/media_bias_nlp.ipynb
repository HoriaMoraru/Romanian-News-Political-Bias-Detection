{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c6412f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "\n",
    "if platform.system() == \"Windows\":\n",
    "    os.chdir(\"C:/Users/horia/Desktop/Licenta/NewsBiasDetection\")\n",
    "else:\n",
    "    os.chdir(\"/workspace\")\n",
    "\n",
    "import torch\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df =pd.read_csv(\"dataset/romanian_political_articles_v1.csv\")\n",
    "\n",
    "df = df.dropna(subset=[\"maintext\", \"source_domain\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3971a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4691/4691 [00:00<00:00, 4767.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>date_publish</th>\n",
       "      <th>description</th>\n",
       "      <th>maintext</th>\n",
       "      <th>source_domain</th>\n",
       "      <th>authors</th>\n",
       "      <th>cleantext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.realitatea.net/stiri/politica/ion-...</td>\n",
       "      <td>Ion Cristoiu: Ilie Bolojan și rețeaua sa duc o...</td>\n",
       "      <td>2025-04-08 08:38:37</td>\n",
       "      <td>Ilie Bolojan si reteaua sa duc o politica anti...</td>\n",
       "      <td>\"Domnul Sprînceană a intervenit, nu știu ce l-...</td>\n",
       "      <td>www.realitatea.net</td>\n",
       "      <td>Realitatea.NET</td>\n",
       "      <td>\"Domnul Sprînceană a intervenit, nu știu ce l-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.realitatea.net/stiri/politica/scan...</td>\n",
       "      <td>Scandalurile prin care a devenit celebru candi...</td>\n",
       "      <td>2025-04-13 13:09:59</td>\n",
       "      <td>Tupeu incredibil din partea lui Nicusor Dan! S...</td>\n",
       "      <td>Activistă și ea din zona soroșistă ce a venit ...</td>\n",
       "      <td>www.realitatea.net</td>\n",
       "      <td>Georgiana Balaban</td>\n",
       "      <td>Activistă și ea din zona soroșistă ce a venit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.realitatea.net/stiri/politica/crin...</td>\n",
       "      <td>Crin Antonescu: „Nicușor dă prea puțină apă, P...</td>\n",
       "      <td>2025-04-12 20:54:54</td>\n",
       "      <td>,,Nicusor Dan da prea putina apa si Ponta prea...</td>\n",
       "      <td>Crin Antonescu: „Ei promit lapte și miere, dar...</td>\n",
       "      <td>www.realitatea.net</td>\n",
       "      <td>Georgiana Balaban</td>\n",
       "      <td>Crin Antonescu: „Domnul Nicușor Dan după ce a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.realitatea.net/stiri/politica/geor...</td>\n",
       "      <td>George Simion: „Ideea de tur doi înapoi înseam...</td>\n",
       "      <td>2025-04-12 21:50:26</td>\n",
       "      <td>,,Ideea de tur doi inapoi inseamna revenirea l...</td>\n",
       "      <td>Totul pentru a evita o situație asemănătoare c...</td>\n",
       "      <td>www.realitatea.net</td>\n",
       "      <td>Georgiana Balaban</td>\n",
       "      <td>Totul pentru a evita o situație asemănătoare c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://www.realitatea.net/stiri/politica/flor...</td>\n",
       "      <td>Florin Zamfirescu: „Oamenii nu mai au cu cine ...</td>\n",
       "      <td>2025-04-13 08:54:16</td>\n",
       "      <td>Florin Zamfirescu a vorbit in exclusivitate la...</td>\n",
       "      <td>Actorul spune că românii sunt îngenuncheați și...</td>\n",
       "      <td>www.realitatea.net</td>\n",
       "      <td>Georgiana Balaban</td>\n",
       "      <td>Actorul spune că românii sunt îngenuncheați și...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.realitatea.net/stiri/politica/ion-...   \n",
       "1  https://www.realitatea.net/stiri/politica/scan...   \n",
       "2  https://www.realitatea.net/stiri/politica/crin...   \n",
       "5  https://www.realitatea.net/stiri/politica/geor...   \n",
       "6  https://www.realitatea.net/stiri/politica/flor...   \n",
       "\n",
       "                                               title         date_publish  \\\n",
       "0  Ion Cristoiu: Ilie Bolojan și rețeaua sa duc o...  2025-04-08 08:38:37   \n",
       "1  Scandalurile prin care a devenit celebru candi...  2025-04-13 13:09:59   \n",
       "2  Crin Antonescu: „Nicușor dă prea puțină apă, P...  2025-04-12 20:54:54   \n",
       "5  George Simion: „Ideea de tur doi înapoi înseam...  2025-04-12 21:50:26   \n",
       "6  Florin Zamfirescu: „Oamenii nu mai au cu cine ...  2025-04-13 08:54:16   \n",
       "\n",
       "                                         description  \\\n",
       "0  Ilie Bolojan si reteaua sa duc o politica anti...   \n",
       "1  Tupeu incredibil din partea lui Nicusor Dan! S...   \n",
       "2  ,,Nicusor Dan da prea putina apa si Ponta prea...   \n",
       "5  ,,Ideea de tur doi inapoi inseamna revenirea l...   \n",
       "6  Florin Zamfirescu a vorbit in exclusivitate la...   \n",
       "\n",
       "                                            maintext       source_domain  \\\n",
       "0  \"Domnul Sprînceană a intervenit, nu știu ce l-...  www.realitatea.net   \n",
       "1  Activistă și ea din zona soroșistă ce a venit ...  www.realitatea.net   \n",
       "2  Crin Antonescu: „Ei promit lapte și miere, dar...  www.realitatea.net   \n",
       "5  Totul pentru a evita o situație asemănătoare c...  www.realitatea.net   \n",
       "6  Actorul spune că românii sunt îngenuncheați și...  www.realitatea.net   \n",
       "\n",
       "             authors                                          cleantext  \n",
       "0     Realitatea.NET  \"Domnul Sprînceană a intervenit, nu știu ce l-...  \n",
       "1  Georgiana Balaban  Activistă și ea din zona soroșistă ce a venit ...  \n",
       "2  Georgiana Balaban  Crin Antonescu: „Domnul Nicușor Dan după ce a ...  \n",
       "5  Georgiana Balaban  Totul pentru a evita o situație asemănătoare c...  \n",
       "6  Georgiana Balaban  Actorul spune că românii sunt îngenuncheați și...  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import spacy\n",
    "\n",
    "nlp_ro = spacy.load(\"ro_core_news_sm\")\n",
    "\n",
    "def remove_quotes(text):\n",
    "    return re.sub(r'[\\'\"„”][^\\'\"„”]{1,300}?[\\'\"„”]', '', text)\n",
    "\n",
    "def remove_html(text):\n",
    "    return re.sub(r\"<.*?>\", \"\", text)\n",
    "\n",
    "def remove_digits_keep_years(text):\n",
    "    return re.sub(r'\\b(?!20\\d{2})\\d+\\b', '', text)\n",
    "\n",
    "def remove_urls(text):\n",
    "    return re.sub(r'http\\S+', '', text)\n",
    "\n",
    "def normalize_whitespace(text):\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "def remove_weird_punctuation(text):\n",
    "    return re.sub(r'[\\*\\•\\·@~^_`+=\\\\|]', '', text)\n",
    "\n",
    "def preprocess_for_romanian_models(text):\n",
    "    return text.replace(\"ţ\", \"ț\").replace(\"ş\", \"ș\").replace(\"Ţ\", \"Ț\").replace(\"Ş\", \"Ș\")\n",
    "\n",
    "def preprocess_text(text : str):\n",
    "    if not text or len(text.strip()) == 0:\n",
    "        return \"\"\n",
    "\n",
    "    text = preprocess_for_romanian_models(text)\n",
    "\n",
    "    text = remove_html(text)\n",
    "\n",
    "    text = remove_quotes(text)\n",
    "\n",
    "    text = remove_urls(text)\n",
    "\n",
    "    text = remove_digits_keep_years(text)\n",
    "\n",
    "    text = remove_weird_punctuation(text)\n",
    "\n",
    "    text = normalize_whitespace(text)\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "df['cleantext'] = df['maintext'].progress_apply(preprocess_text)\n",
    "\n",
    "df = df[df['cleantext'].str.split().str.len() > 100]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69d11a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "  1%|          | 47/4052 [00:19<27:28,  2.43it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[160]\u001b[39m\u001b[32m, line 66\u001b[39m\n\u001b[32m     62\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNER failed:\u001b[39m\u001b[33m\"\u001b[39m, e)\n\u001b[32m     64\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(entities)\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mner\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcleantext\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprogress_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextract_named_entities\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m df.head()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\horia\\Desktop\\Licenta\\NewsBiasDetection\\.venv\\Lib\\site-packages\\tqdm\\std.py:917\u001b[39m, in \u001b[36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[39m\u001b[34m(df, func, *args, **kwargs)\u001b[39m\n\u001b[32m    914\u001b[39m \u001b[38;5;66;03m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[32m    915\u001b[39m \u001b[38;5;66;03m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m917\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_function\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    919\u001b[39m     t.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\horia\\Desktop\\Licenta\\NewsBiasDetection\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4789\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4790\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4791\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4796\u001b[39m     **kwargs,\n\u001b[32m   4797\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4798\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4799\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4800\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4915\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4916\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4917\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4918\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4919\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4920\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4921\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4922\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4923\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4924\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\horia\\Desktop\\Licenta\\NewsBiasDetection\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1424\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1426\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1427\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\horia\\Desktop\\Licenta\\NewsBiasDetection\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1501\u001b[39m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[32m   1502\u001b[39m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[32m   1503\u001b[39m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[32m   1504\u001b[39m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[32m   1505\u001b[39m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[32m   1506\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj.dtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1507\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1508\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[32m   1509\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1511\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1512\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1513\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1514\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\horia\\Desktop\\Licenta\\NewsBiasDetection\\.venv\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    918\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    919\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m921\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\horia\\Desktop\\Licenta\\NewsBiasDetection\\.venv\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mlib.pyx:2972\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\horia\\Desktop\\Licenta\\NewsBiasDetection\\.venv\\Lib\\site-packages\\tqdm\\std.py:912\u001b[39m, in \u001b[36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    906\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    907\u001b[39m     \u001b[38;5;66;03m# update tbar correctly\u001b[39;00m\n\u001b[32m    908\u001b[39m     \u001b[38;5;66;03m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[32m    909\u001b[39m     \u001b[38;5;66;03m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[32m    910\u001b[39m     \u001b[38;5;66;03m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[32m    911\u001b[39m     t.update(n=\u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t.total \u001b[38;5;129;01mor\u001b[39;00m t.n < t.total \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m912\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[160]\u001b[39m\u001b[32m, line 58\u001b[39m, in \u001b[36mextract_named_entities\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m     55\u001b[39m             entity_group = entity[\u001b[33m'\u001b[39m\u001b[33mentity_group\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     56\u001b[39m             word = entity[\u001b[33m'\u001b[39m\u001b[33mword\u001b[39m\u001b[33m'\u001b[39m].strip(\u001b[33m\"\u001b[39m\u001b[33m .,:;\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m?!/><)(*&^\u001b[39m\u001b[33m%\u001b[39m\u001b[33m$@+-=_-”„“\u001b[39m\u001b[33m\"\u001b[39m).replace(\u001b[33m\"\u001b[39m\u001b[33m##\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m entity_group \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mPERSON\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mGPE\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mis_pronoun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     59\u001b[39m                 entities.add(word)\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[160]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mis_pronoun\u001b[39m\u001b[34m(word)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mis_pronoun\u001b[39m(word):\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28many\u001b[39m(token.pos_ == \u001b[33m\"\u001b[39m\u001b[33mPRON\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[43mnlp_ro\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\horia\\Desktop\\Licenta\\NewsBiasDetection\\.venv\\Lib\\site-packages\\spacy\\language.py:1052\u001b[39m, in \u001b[36mLanguage.__call__\u001b[39m\u001b[34m(self, text, disable, component_cfg)\u001b[39m\n\u001b[32m   1050\u001b[39m     error_handler = proc.get_error_handler()\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1052\u001b[39m     doc = \u001b[43mproc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcomponent_cfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m   1053\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1054\u001b[39m     \u001b[38;5;66;03m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[32m   1055\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors.E109.format(name=name)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\horia\\Desktop\\Licenta\\NewsBiasDetection\\.venv\\Lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx:52\u001b[39m, in \u001b[36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\horia\\Desktop\\Licenta\\NewsBiasDetection\\.venv\\Lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx:264\u001b[39m, in \u001b[36mspacy.pipeline.transition_parser.Parser.predict\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\horia\\Desktop\\Licenta\\NewsBiasDetection\\.venv\\Lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx:285\u001b[39m, in \u001b[36mspacy.pipeline.transition_parser.Parser.greedy_parse\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\horia\\Desktop\\Licenta\\NewsBiasDetection\\.venv\\Lib\\site-packages\\thinc\\model.py:334\u001b[39m, in \u001b[36mModel.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT) -> OutT:\n\u001b[32m    331\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[32m    332\u001b[39m \u001b[33;03m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[32m    333\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\horia\\Desktop\\Licenta\\NewsBiasDetection\\.venv\\Lib\\site-packages\\spacy\\ml\\tb_framework.py:34\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(model, X, is_train)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(model, X, is_train):\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     step_model = \u001b[43mParserStepModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m        \u001b[49m\u001b[43munseen_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43munseen_classes\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_upper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhas_upper\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m step_model, step_model.finish_steps\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\horia\\Desktop\\Licenta\\NewsBiasDetection\\.venv\\Lib\\site-packages\\spacy\\ml\\parser_model.pyx:250\u001b[39m, in \u001b[36mspacy.ml.parser_model.ParserStepModel.__init__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\horia\\Desktop\\Licenta\\NewsBiasDetection\\.venv\\Lib\\site-packages\\thinc\\model.py:310\u001b[39m, in \u001b[36mModel.__call__\u001b[39m\u001b[34m(self, X, is_train)\u001b[39m\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) -> Tuple[OutT, Callable]:\n\u001b[32m    308\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[32m    309\u001b[39m \u001b[33;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\horia\\Desktop\\Licenta\\NewsBiasDetection\\.venv\\Lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(model, X, is_train)\u001b[39m\n\u001b[32m     52\u001b[39m callbacks = []\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model.layers:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     Y, inc_layer_grad = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m     callbacks.append(inc_layer_grad)\n\u001b[32m     56\u001b[39m     X = Y\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\horia\\Desktop\\Licenta\\NewsBiasDetection\\.venv\\Lib\\site-packages\\thinc\\model.py:310\u001b[39m, in \u001b[36mModel.__call__\u001b[39m\u001b[34m(self, X, is_train)\u001b[39m\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) -> Tuple[OutT, Callable]:\n\u001b[32m    308\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[32m    309\u001b[39m \u001b[33;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\horia\\Desktop\\Licenta\\NewsBiasDetection\\.venv\\Lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(model, X, is_train)\u001b[39m\n\u001b[32m     52\u001b[39m callbacks = []\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model.layers:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     Y, inc_layer_grad = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m     callbacks.append(inc_layer_grad)\n\u001b[32m     56\u001b[39m     X = Y\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\horia\\Desktop\\Licenta\\NewsBiasDetection\\.venv\\Lib\\site-packages\\thinc\\model.py:310\u001b[39m, in \u001b[36mModel.__call__\u001b[39m\u001b[34m(self, X, is_train)\u001b[39m\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) -> Tuple[OutT, Callable]:\n\u001b[32m    308\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[32m    309\u001b[39m \u001b[33;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\horia\\Desktop\\Licenta\\NewsBiasDetection\\.venv\\Lib\\site-packages\\thinc\\layers\\with_array.py:42\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(model, Xseq, is_train)\u001b[39m\n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model.layers[\u001b[32m0\u001b[39m](Xseq, is_train)\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], \u001b[43m_list_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXseq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\horia\\Desktop\\Licenta\\NewsBiasDetection\\.venv\\Lib\\site-packages\\thinc\\layers\\with_array.py:77\u001b[39m, in \u001b[36m_list_forward\u001b[39m\u001b[34m(model, Xs, is_train)\u001b[39m\n\u001b[32m     75\u001b[39m lengths = NUMPY_OPS.asarray1i([\u001b[38;5;28mlen\u001b[39m(seq) \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m Xs])\n\u001b[32m     76\u001b[39m Xf = layer.ops.flatten(Xs, pad=pad)\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m Yf, get_dXf = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbackprop\u001b[39m(dYs: ListXd) -> ListXd:\n\u001b[32m     80\u001b[39m     dYf = layer.ops.flatten(dYs, pad=pad)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\horia\\Desktop\\Licenta\\NewsBiasDetection\\.venv\\Lib\\site-packages\\thinc\\model.py:310\u001b[39m, in \u001b[36mModel.__call__\u001b[39m\u001b[34m(self, X, is_train)\u001b[39m\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) -> Tuple[OutT, Callable]:\n\u001b[32m    308\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[32m    309\u001b[39m \u001b[33;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\horia\\Desktop\\Licenta\\NewsBiasDetection\\.venv\\Lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(model, X, is_train)\u001b[39m\n\u001b[32m     52\u001b[39m callbacks = []\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model.layers:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     Y, inc_layer_grad = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m     callbacks.append(inc_layer_grad)\n\u001b[32m     56\u001b[39m     X = Y\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\horia\\Desktop\\Licenta\\NewsBiasDetection\\.venv\\Lib\\site-packages\\thinc\\model.py:310\u001b[39m, in \u001b[36mModel.__call__\u001b[39m\u001b[34m(self, X, is_train)\u001b[39m\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) -> Tuple[OutT, Callable]:\n\u001b[32m    308\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[32m    309\u001b[39m \u001b[33;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\horia\\Desktop\\Licenta\\NewsBiasDetection\\.venv\\Lib\\site-packages\\thinc\\layers\\residual.py:41\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(model, X, is_train)\u001b[39m\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     39\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m d_output + dX\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m Y, backprop_layer = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [X[i] + Y[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X))], backprop\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\horia\\Desktop\\Licenta\\NewsBiasDetection\\.venv\\Lib\\site-packages\\thinc\\model.py:310\u001b[39m, in \u001b[36mModel.__call__\u001b[39m\u001b[34m(self, X, is_train)\u001b[39m\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) -> Tuple[OutT, Callable]:\n\u001b[32m    308\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[32m    309\u001b[39m \u001b[33;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\horia\\Desktop\\Licenta\\NewsBiasDetection\\.venv\\Lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(model, X, is_train)\u001b[39m\n\u001b[32m     52\u001b[39m callbacks = []\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model.layers:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     Y, inc_layer_grad = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m     callbacks.append(inc_layer_grad)\n\u001b[32m     56\u001b[39m     X = Y\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\horia\\Desktop\\Licenta\\NewsBiasDetection\\.venv\\Lib\\site-packages\\thinc\\model.py:310\u001b[39m, in \u001b[36mModel.__call__\u001b[39m\u001b[34m(self, X, is_train)\u001b[39m\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) -> Tuple[OutT, Callable]:\n\u001b[32m    308\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[32m    309\u001b[39m \u001b[33;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\horia\\Desktop\\Licenta\\NewsBiasDetection\\.venv\\Lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(model, X, is_train)\u001b[39m\n\u001b[32m     52\u001b[39m callbacks = []\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model.layers:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     Y, inc_layer_grad = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m     callbacks.append(inc_layer_grad)\n\u001b[32m     56\u001b[39m     X = Y\n",
      "    \u001b[31m[... skipping similar frames: Model.__call__ at line 310 (1 times)]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\horia\\Desktop\\Licenta\\NewsBiasDetection\\.venv\\Lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(model, X, is_train)\u001b[39m\n\u001b[32m     52\u001b[39m callbacks = []\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model.layers:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     Y, inc_layer_grad = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m     callbacks.append(inc_layer_grad)\n\u001b[32m     56\u001b[39m     X = Y\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\horia\\Desktop\\Licenta\\NewsBiasDetection\\.venv\\Lib\\site-packages\\thinc\\model.py:310\u001b[39m, in \u001b[36mModel.__call__\u001b[39m\u001b[34m(self, X, is_train)\u001b[39m\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) -> Tuple[OutT, Callable]:\n\u001b[32m    308\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[32m    309\u001b[39m \u001b[33;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\horia\\Desktop\\Licenta\\NewsBiasDetection\\.venv\\Lib\\site-packages\\thinc\\layers\\maxout.py:52\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(model, X, is_train)\u001b[39m\n\u001b[32m     50\u001b[39m W = model.get_param(\u001b[33m\"\u001b[39m\u001b[33mW\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     51\u001b[39m W = model.ops.reshape2f(W, nO * nP, nI)\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m Y = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgemm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrans2\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m Y += model.ops.reshape1f(b, nO * nP)\n\u001b[32m     54\u001b[39m Z = model.ops.reshape3f(Y, Y.shape[\u001b[32m0\u001b[39m], nO, nP)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, AutoConfig, pipeline\n",
    "import spacy\n",
    "\n",
    "def get_romanian_ner_nlp_pipeline():\n",
    "    romanian_ner_model = \"dumitrescustefan/bert-base-romanian-ner\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(romanian_ner_model, model_max_length=512)\n",
    "\n",
    "    config = AutoConfig.from_pretrained(romanian_ner_model)\n",
    "    config.id2label = {\n",
    "        0: 'O', 1: 'B-PERSON', 2: 'I-PERSON', 3: 'B-ORG', 4: 'I-ORG', 5: 'B-GPE', 6: 'I-GPE', 7: 'B-LOC',\n",
    "        8: 'I-LOC', 9: 'B-NAT_REL_POL', 10: 'I-NAT_REL_POL', 11: 'B-EVENT', 12: 'I-EVENT', 13: 'B-LANGUAGE',\n",
    "        14: 'I-LANGUAGE', 15: 'B-WORK_OF_ART', 16: 'I-WORK_OF_ART', 17: 'B-DATETIME', 18: 'I-DATETIME',\n",
    "        19: 'B-PERIOD', 20: 'I-PERIOD', 21: 'B-MONEY', 22: 'I-MONEY', 23: 'B-QUANTITY', 24: 'I-QUANTITY',\n",
    "        25: 'B-NUMERIC', 26: 'I-NUMERIC', 27: 'B-ORDINAL', 28: 'I-ORDINAL', 29: 'B-FACILITY', 30: 'I-FACILITY'\n",
    "    }\n",
    "\n",
    "    model = AutoModelForTokenClassification.from_pretrained(romanian_ner_model, config=config)\n",
    "\n",
    "    return pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy='simple', device=device)\n",
    "\n",
    "ner_pipeline = get_romanian_ner_nlp_pipeline()\n",
    "\n",
    "def is_pronoun(word):\n",
    "    return any(token.pos_ == \"PRON\" for token in nlp_ro(word))\n",
    "\n",
    "def chunk_sentences(doc, tokenizer, max_tokens=512):\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_len = 0\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        tokens = tokenizer.tokenize(sent.text)\n",
    "        if current_len + len(tokens) > max_tokens:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = []\n",
    "            current_len = 0\n",
    "        current_chunk.append(sent.text)\n",
    "        current_len += len(tokens)\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def extract_named_entities(text):\n",
    "    entities = set()\n",
    "\n",
    "    try:\n",
    "        doc = nlp_ro(text)\n",
    "        chunks = chunk_sentences(doc, ner_pipeline.tokenizer)\n",
    "\n",
    "        results = ner_pipeline(chunks, batch_size=8)\n",
    "\n",
    "        for result in results:\n",
    "            for entity in result:\n",
    "                entity_group = entity['entity_group']\n",
    "                word = entity['word'].strip(\" .,:;\\\"'?!/><)(*&^%$@+-=_-”„“\").replace(\"##\", \"\")\n",
    "\n",
    "                if entity_group in ['PERSON', 'GPE'] and not is_pronoun(word):\n",
    "                    entities.add(word)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"NER failed:\", e)\n",
    "\n",
    "    return list(entities)\n",
    "\n",
    "df['ner'] = df['cleantext'].progress_apply(extract_named_entities)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44765a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "def get_romistral_pipeline():\n",
    "    romistral_model = \"OpenLLM-Ro/RoMistral-7b-Instruct\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(romistral_model)\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(romistral_model, device_map=\"auto\")\n",
    "\n",
    "    return pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "romistral_pipeline = get_romistral_pipeline()\n",
    "\n",
    "def format_sentiment_prompt(entity, sentence):\n",
    "    return (\n",
    "        f\"Clasifică sentimentul exprimat față de {entity} în următoarea propoziție.\\n\"\n",
    "        f\"Răspunsul trebuie să fie un singur cuvânt: pozitiv, negativ sau neutru.\\n\\n\"\n",
    "        f\"{sentence}\"\n",
    "    )\n",
    "\n",
    "def romistral_batch_sentiment(pairs, max_new_tokens=20):\n",
    "    prompts = [format_sentiment_prompt(ent, sent) for ent, sent in pairs]\n",
    "\n",
    "    responses = romistral_pipeline(\n",
    "        prompts,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=False,\n",
    "        return_full_text=False\n",
    "    )\n",
    "\n",
    "    results = []\n",
    "    for (entity, sentence), output in zip(pairs, responses):\n",
    "        if isinstance(output, list):\n",
    "            output = output[0]\n",
    "\n",
    "        text = output.get('generated_text', output.get('text', '')).strip().lower()\n",
    "\n",
    "        match = re.search(r\"\\b(pozitiv|negativ|neutru)\\b\", text, re.IGNORECASE)\n",
    "        sentiment = match.group(1).upper() if match else \"UNKNOWN\"\n",
    "\n",
    "        results.append({\n",
    "            \"entity\": entity,\n",
    "            \"sentence\": sentence,\n",
    "            \"sentiment\": sentiment\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_ner_sentiments(text, ner_entities):\n",
    "    doc = nlp_ro(text)\n",
    "\n",
    "    pairs = []\n",
    "    for entity in ner_entities:\n",
    "        for sent in doc.sents:\n",
    "            sent_text = sent.text.strip()\n",
    "            if entity.lower() in sent_text.lower():\n",
    "                pairs.append((entity, sent_text))\n",
    "\n",
    "    if not pairs:\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        return romistral_batch_sentiment(pairs)\n",
    "    except Exception as e:\n",
    "        print(\"Sentiment analysis failed:\", e)\n",
    "        return []\n",
    "\n",
    "\n",
    "df['ner_sentiments'] = df.progress_apply(lambda row: get_ner_sentiments(row['cleantext'], row['ner']), axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea439bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'negative', 1: 'positive'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4016/4016 [7:43:12<00:00,  6.92s/it]   \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>date_publish</th>\n",
       "      <th>description</th>\n",
       "      <th>maintext</th>\n",
       "      <th>source_domain</th>\n",
       "      <th>authors</th>\n",
       "      <th>cleantext</th>\n",
       "      <th>ner</th>\n",
       "      <th>ner_sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.realitatea.net/stiri/politica/scan...</td>\n",
       "      <td>Scandalurile prin care a devenit celebru candi...</td>\n",
       "      <td>2025-04-13 13:09:59</td>\n",
       "      <td>Tupeu incredibil din partea lui Nicusor Dan! S...</td>\n",
       "      <td>Activistă și ea din zona soroșistă ce a venit ...</td>\n",
       "      <td>www.realitatea.net</td>\n",
       "      <td>Georgiana Balaban</td>\n",
       "      <td>Activistă și ea din zona soroșistă ce a venit ...</td>\n",
       "      <td>[PERIOD, Bucureștiul, domnul Nicușor Dan, pers...</td>\n",
       "      <td>[{'entity': 'PERIOD', 'sentence': 'Activistă ș...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.realitatea.net/stiri/politica/crin...</td>\n",
       "      <td>Crin Antonescu: „Nicușor dă prea puțină apă, P...</td>\n",
       "      <td>2025-04-12 20:54:54</td>\n",
       "      <td>,,Nicusor Dan da prea putina apa si Ponta prea...</td>\n",
       "      <td>Crin Antonescu: „Ei promit lapte și miere, dar...</td>\n",
       "      <td>www.realitatea.net</td>\n",
       "      <td>Georgiana Balaban</td>\n",
       "      <td>Crin Antonescu Ei promit lapte și miere dar nu...</td>\n",
       "      <td>[băieți, candidați, Mahomed, personaj, oamenii...</td>\n",
       "      <td>[{'entity': 'băieți', 'sentence': 'dar poate c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.realitatea.net/stiri/politica/lasc...</td>\n",
       "      <td>Lasconi: „Nicușor Dan mi-a cerut să mă retrag ...</td>\n",
       "      <td>2025-04-12 19:02:32</td>\n",
       "      <td>,,Nicusor Dan mi-a cerut sa ma duc la Stejarii...</td>\n",
       "      <td>Candidata la prezidențiale trădată de propriul...</td>\n",
       "      <td>www.realitatea.net</td>\n",
       "      <td>Georgiana Balaban</td>\n",
       "      <td>Candidata la prezidențiale trădată de propriul...</td>\n",
       "      <td>[Capitalei, Ciucă, Zaherman, edilul, Nicușor D...</td>\n",
       "      <td>[{'entity': 'Capitalei', 'sentence': 'Candidat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.realitatea.net/stiri/politica/geor...</td>\n",
       "      <td>George Simion: „Ideea de tur doi înapoi înseam...</td>\n",
       "      <td>2025-04-12 21:50:26</td>\n",
       "      <td>,,Ideea de tur doi inapoi inseamna revenirea l...</td>\n",
       "      <td>Totul pentru a evita o situație asemănătoare c...</td>\n",
       "      <td>www.realitatea.net</td>\n",
       "      <td>Georgiana Balaban</td>\n",
       "      <td>Totul pentru a evita o situație asemănătoare c...</td>\n",
       "      <td>[George Simion, domnul Călin Georgescu, președ...</td>\n",
       "      <td>[{'entity': 'George Simion', 'sentence': 'PERI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://www.realitatea.net/stiri/politica/flor...</td>\n",
       "      <td>Florin Zamfirescu: „Oamenii nu mai au cu cine ...</td>\n",
       "      <td>2025-04-13 08:54:16</td>\n",
       "      <td>Florin Zamfirescu a vorbit in exclusivitate la...</td>\n",
       "      <td>Actorul spune că românii sunt îngenuncheați și...</td>\n",
       "      <td>www.realitatea.net</td>\n",
       "      <td>Georgiana Balaban</td>\n",
       "      <td>Actorul spune că românii sunt îngenuncheați și...</td>\n",
       "      <td>[popor, România, Ponta, domne omul, Florin Zam...</td>\n",
       "      <td>[{'entity': 'popor', 'sentence': 'Actorul spun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "1  https://www.realitatea.net/stiri/politica/scan...   \n",
       "2  https://www.realitatea.net/stiri/politica/crin...   \n",
       "3  https://www.realitatea.net/stiri/politica/lasc...   \n",
       "5  https://www.realitatea.net/stiri/politica/geor...   \n",
       "6  https://www.realitatea.net/stiri/politica/flor...   \n",
       "\n",
       "                                               title         date_publish  \\\n",
       "1  Scandalurile prin care a devenit celebru candi...  2025-04-13 13:09:59   \n",
       "2  Crin Antonescu: „Nicușor dă prea puțină apă, P...  2025-04-12 20:54:54   \n",
       "3  Lasconi: „Nicușor Dan mi-a cerut să mă retrag ...  2025-04-12 19:02:32   \n",
       "5  George Simion: „Ideea de tur doi înapoi înseam...  2025-04-12 21:50:26   \n",
       "6  Florin Zamfirescu: „Oamenii nu mai au cu cine ...  2025-04-13 08:54:16   \n",
       "\n",
       "                                         description  \\\n",
       "1  Tupeu incredibil din partea lui Nicusor Dan! S...   \n",
       "2  ,,Nicusor Dan da prea putina apa si Ponta prea...   \n",
       "3  ,,Nicusor Dan mi-a cerut sa ma duc la Stejarii...   \n",
       "5  ,,Ideea de tur doi inapoi inseamna revenirea l...   \n",
       "6  Florin Zamfirescu a vorbit in exclusivitate la...   \n",
       "\n",
       "                                            maintext       source_domain  \\\n",
       "1  Activistă și ea din zona soroșistă ce a venit ...  www.realitatea.net   \n",
       "2  Crin Antonescu: „Ei promit lapte și miere, dar...  www.realitatea.net   \n",
       "3  Candidata la prezidențiale trădată de propriul...  www.realitatea.net   \n",
       "5  Totul pentru a evita o situație asemănătoare c...  www.realitatea.net   \n",
       "6  Actorul spune că românii sunt îngenuncheați și...  www.realitatea.net   \n",
       "\n",
       "             authors                                          cleantext  \\\n",
       "1  Georgiana Balaban  Activistă și ea din zona soroșistă ce a venit ...   \n",
       "2  Georgiana Balaban  Crin Antonescu Ei promit lapte și miere dar nu...   \n",
       "3  Georgiana Balaban  Candidata la prezidențiale trădată de propriul...   \n",
       "5  Georgiana Balaban  Totul pentru a evita o situație asemănătoare c...   \n",
       "6  Georgiana Balaban  Actorul spune că românii sunt îngenuncheați și...   \n",
       "\n",
       "                                                 ner  \\\n",
       "1  [PERIOD, Bucureștiul, domnul Nicușor Dan, pers...   \n",
       "2  [băieți, candidați, Mahomed, personaj, oamenii...   \n",
       "3  [Capitalei, Ciucă, Zaherman, edilul, Nicușor D...   \n",
       "5  [George Simion, domnul Călin Georgescu, președ...   \n",
       "6  [popor, România, Ponta, domne omul, Florin Zam...   \n",
       "\n",
       "                                      ner_sentiments  \n",
       "1  [{'entity': 'PERIOD', 'sentence': 'Activistă ș...  \n",
       "2  [{'entity': 'băieți', 'sentence': 'dar poate c...  \n",
       "3  [{'entity': 'Capitalei', 'sentence': 'Candidat...  \n",
       "5  [{'entity': 'George Simion', 'sentence': 'PERI...  \n",
       "6  [{'entity': 'popor', 'sentence': 'Actorul spun...  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "def get_romanian_sentiment_pipeline():\n",
    "    romanian_sentiment_model = \"DGurgurov/xlm-r_romanian_sentiment\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(romanian_sentiment_model, model_max_length=512)\n",
    "\n",
    "    config = AutoConfig.from_pretrained(romanian_sentiment_model)\n",
    "    config.id2label = {0: \"negative\", 1: \"positive\"}\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(romanian_sentiment_model, config=config)\n",
    "    print(model.config.id2label)\n",
    "\n",
    "    return pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "sentiment_pipeline = get_romanian_sentiment_pipeline()\n",
    "\n",
    "def get_sentiment(sentiment_output, neutral_threshhold=0.63):\n",
    "    label = sentiment_output['label']\n",
    "    score = sentiment_output['score']\n",
    "\n",
    "    if score <= neutral_threshhold:\n",
    "        return 'neutral'\n",
    "\n",
    "    return label\n",
    "\n",
    "def get_ner_sentiments(text, ner_entities, max_tokens=512):\n",
    "    sentiments = []\n",
    "\n",
    "    doc = nlp_ro(text)\n",
    "\n",
    "    for entity in ner_entities:\n",
    "        related_sentences = [sent.text.strip() for sent in doc.sents if entity.lower() in sent.text.lower()]\n",
    "\n",
    "        if not related_sentences:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            results = sentiment_pipeline(related_sentences, truncation=True, max_length=max_tokens)\n",
    "\n",
    "            for sentence, sentiment in zip(related_sentences, results):\n",
    "                sentiment_label = get_sentiment(sentiment)\n",
    "\n",
    "                sentiments.append({\n",
    "                    'entity': entity,\n",
    "                    'sentence': sentence,\n",
    "                    'sentiment': sentiment_label,\n",
    "                    'score': round(sentiment['score'], 3)\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(\"Sentiment analysis failed:\", e)\n",
    "            continue\n",
    "\n",
    "    return sentiments\n",
    "\n",
    "df['ner_sentiments'] = df.progress_apply(lambda row: get_ner_sentiments(row['cleantext'], row['ner']), axis=1)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
